{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# 全局攻击 数据集：异配图数据集；代理模型：H2GCN；网格搜索，找到最佳lr和epochs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import torch.optim as optim\n",
    "import scipy.sparse as sp\n",
    "from copy import deepcopy\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_sparse import SparseTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *\n",
    "from H2GCN import H2GCN\n",
    "from gcn import GCN\n",
    "from DICE import DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟命令行参数\n",
    "class Args:\n",
    "    def __init__(self, dataset='cora', lr=0.001, epochs=2000):\n",
    "        self.seed = 15\n",
    "        self.dataset = dataset \n",
    "        self.input_size = 0\n",
    "        self.output_size = 0\n",
    "        self.hidden_size = 64\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.drop_prob = 0.5\n",
    "        self.round = 2\n",
    "        self.train_ratio = 0.6\n",
    "        self.patience = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# 定义要尝试的学习率和 epochs 的候选值\n",
    "lr_values = [0.0001, 0.001, 0.01]\n",
    "epochs_values = [2000]\n",
    "\n",
    "# 用于保存最佳结果的变量\n",
    "best_lr = None\n",
    "best_epochs = None\n",
    "best_accuracy = 0.0  # 假设是准确率作为评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSR(spt):\n",
    "    rowptr, col, value = spt.csr()\n",
    "    mat = sp.csr_matrix((value, col, rowptr)).tolil()\n",
    "    mat.setdiag(0)\n",
    "    return mat.tocsr()\n",
    "\n",
    "def get_adj_2hop():\n",
    "    edge_index = to_undirected(g.edges())\n",
    "    adj = SparseTensor(row=edge_index[0], col=edge_index[1],\n",
    "                        sparse_sizes=(g.num_nodes(), g.num_nodes())).fill_value(1.0)\n",
    "    adj2 = adj.matmul(adj).fill_value(1.0)\n",
    "    adj_2hop = (toCSR(adj2) - toCSR(adj)) > 0\n",
    "    adj_2hop = SparseTensor.from_scipy(adj_2hop).fill_value(1.0)\n",
    "\n",
    "    adj = adj.to(device)\n",
    "    adj_2hop = adj_2hop.to(device)\n",
    "\n",
    "    return adj, adj_2hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(args):\n",
    "    # H2GCN模型初始化\n",
    "    # 使用torch.unique()函数找到张量中的唯一值\n",
    "    unique_classes = torch.unique(labels)\n",
    "    # 统计唯一值的数量，即类别数\n",
    "    num_classes = len(unique_classes)\n",
    "    # 模型参数设置\n",
    "    args.input_size = len(features[0])\n",
    "    args.output_size = num_classes\n",
    "\n",
    "    model = H2GCN(in_channels=args.input_size,\n",
    "                hidden_channels=args.hidden_size,\n",
    "                out_channels=args.output_size,\n",
    "                drop_prob=args.drop_prob,\n",
    "                round=args.round)\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, adj, adj_2hop, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    logits = model(features, adj, adj_2hop)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    train_loss = loss_fn(logits[train], labels[train])\n",
    "    train_acc = (pred[train] == labels[train]).float().mean()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def evaluate_val(model, adj, adj_2hop):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features, adj, adj_2hop)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    val_acc = (pred[val] == labels[val]).float().mean()\n",
    "    return val_acc\n",
    "\n",
    "def evaluate_test(model, adj, adj_2hop):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features, adj, adj_2hop)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    test_acc = (pred[test] == labels[test]).float().mean()\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "citeseer 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyajing/experiment1/utils.py:220: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep200: train loss: 1.5828 train acc: 0.5583 val acc: 0.5420\n",
      "ep400: train loss: 1.3538 train acc: 0.6500 val acc: 0.5580\n",
      "ep600: train loss: 1.1582 train acc: 0.7250 val acc: 0.5620\n",
      "ep800: train loss: 1.0190 train acc: 0.8083 val acc: 0.5800\n",
      "ep1000: train loss: 0.9144 train acc: 0.8417 val acc: 0.5780\n",
      "ep1200: train loss: 0.7536 train acc: 0.9167 val acc: 0.5820\n",
      "ep1400: train loss: 0.6831 train acc: 0.9417 val acc: 0.5880\n",
      "ep1600: train loss: 0.6194 train acc: 0.9250 val acc: 0.5820\n",
      "ep1800: train loss: 0.5498 train acc: 0.9583 val acc: 0.5860\n",
      "ep2000: train loss: 0.4881 train acc: 0.9500 val acc: 0.5960\n",
      "test acc: 0.5770\n",
      "cuda: True\n",
      "citeseer 6\n",
      "ep200: train loss: 0.6566 train acc: 0.8750 val acc: 0.5660\n",
      "ep400: train loss: 0.1858 train acc: 0.9833 val acc: 0.6020\n",
      "ep600: train loss: 0.1239 train acc: 0.9667 val acc: 0.6040\n",
      "ep800: train loss: 0.0323 train acc: 1.0000 val acc: 0.6020\n",
      "ep1000: train loss: 0.0144 train acc: 1.0000 val acc: 0.6040\n",
      "ep1200: train loss: 0.0097 train acc: 1.0000 val acc: 0.5980\n",
      "ep1400: train loss: 0.0084 train acc: 1.0000 val acc: 0.6060\n",
      "ep1600: train loss: 0.0118 train acc: 1.0000 val acc: 0.6000\n",
      "ep1800: train loss: 0.0044 train acc: 1.0000 val acc: 0.5980\n",
      "ep2000: train loss: 0.0035 train acc: 1.0000 val acc: 0.5920\n",
      "test acc: 0.5980\n",
      "cuda: True\n",
      "citeseer 6\n",
      "ep200: train loss: 0.1354 train acc: 0.9667 val acc: 0.5820\n",
      "ep400: train loss: 0.0468 train acc: 0.9833 val acc: 0.5900\n",
      "ep600: train loss: 0.0048 train acc: 1.0000 val acc: 0.5860\n",
      "ep800: train loss: 0.0116 train acc: 1.0000 val acc: 0.5780\n",
      "ep1000: train loss: 0.0060 train acc: 1.0000 val acc: 0.5720\n",
      "ep1200: train loss: 0.0132 train acc: 1.0000 val acc: 0.5880\n",
      "ep1400: train loss: 0.0176 train acc: 1.0000 val acc: 0.5780\n",
      "ep1600: train loss: 0.0142 train acc: 1.0000 val acc: 0.5500\n",
      "ep1800: train loss: 0.0026 train acc: 1.0000 val acc: 0.5620\n",
      "ep2000: train loss: 0.0037 train acc: 1.0000 val acc: 0.5760\n",
      "test acc: 0.5740\n",
      "Best lr: 0.001\n",
      "Best epochs: 2000\n",
      "Best accuracy: tensor(0.5980, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 网格搜索：尝试每一种 lr 和 epochs 的组合\n",
    "for lr, epochs in itertools.product(lr_values, epochs_values):\n",
    "    # 创建参数对象\n",
    "    args = Args(dataset='citeseer', lr=lr, epochs=epochs)\n",
    "    # 默认dataset为'cora'，可以传入的dataset参数有：choices=['cora', 'citeseer', 'pubmed', 'film', 'squirrel', 'chameleon', 'texas', 'cornell', 'wisconsin']\n",
    "    \n",
    "    # 是否使用cuda\n",
    "    args.cuda = torch.cuda.is_available()\n",
    "    print('cuda: %s' % args.cuda)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    # 加载数据集\n",
    "    g, nclass, features, labels, train, val, test = preprocess_data(args.dataset, args.train_ratio)\n",
    "\n",
    "    features = features.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    idx_train = train.numpy()\n",
    "    idx_test = test.numpy()\n",
    "    idx_val = val.numpy()\n",
    "\n",
    "    train = train.to(device)\n",
    "    test = test.to(device)\n",
    "    val = val.to(device)\n",
    "\n",
    "\n",
    "    adj, adj_2hop = get_adj_2hop()\n",
    "    model = init_model(args)\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=args.lr)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    best_val_acc, best_model = 0., None\n",
    "    for i in range(args.epochs):\n",
    "        train_loss, train_acc = train_model(model, adj, adj_2hop, optimizer, loss_fn)\n",
    "        val_acc = evaluate_val(model, adj, adj_2hop)\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(\"ep{}: train loss: {:.4f} train acc: {:.4f} val acc: {:.4f}\".format(i + 1, train_loss, train_acc, val_acc))\n",
    "\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "    test_acc = evaluate_test(best_model, adj, adj_2hop)\n",
    "    print(\"test acc: {:.4f}\".format(test_acc))\n",
    "    \n",
    "    # 检查是否获得了更好的结果\n",
    "    if test_acc > best_accuracy:\n",
    "        best_lr = lr\n",
    "        best_epochs = epochs\n",
    "        best_accuracy = test_acc\n",
    "\n",
    "# 输出最佳结果\n",
    "print(\"Best lr:\", best_lr)\n",
    "print(\"Best epochs:\", best_epochs)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepRobust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
